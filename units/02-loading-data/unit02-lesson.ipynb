{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 2: Loading Engineering Data\n",
    "\n",
    "After completing this unit, you should be able to:\n",
    "- Understand when to select the `numpy` or `pandas` library for loading data\n",
    "- Load numeric data into a `numpy.ndarray` object\n",
    "- Load mixed-format data into a `pandas.DataFrame` object\n",
    "- Calculate basic statistics for a dataset\n",
    "- Save data to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. The `numpy` package for processing numerical data\n",
    "\n",
    "In Unit 1 we discussed the Python ecosystem, including the fact that there are many add-on packages that extend the basic functionality of Python. One fundamental package for engineering analysis is [`numpy`](https://numpy.org/doc/stable/). Specifically, this package defines an object called the `ndarray` (n-dimensional array), which is used for vector and matrix calculations. As we'll see, this data structure looks similar to the list object that we learned previously but it is far superior for data analysis. The `numpy` package also includes a number of functions for creating, loading, modifying and saving data in the `ndarray` object. The functions in this package are written in C/C++, and take advantage of CPU parallelism to offer high performance (computing speed). Luckily, you don't need to know how this works to benefit from it. \n",
    "\n",
    "To use the `numpy` package, you will add the following `import` line to your code. Note that we are renaming (or, if you prefer, creating an alias for) the `numpy` package as `np` in this instruction. You will commonly find this type of shorthand used, to cut down on clutter later in the program. Now, when we want to reference `numpy`, we'll instead type `np`. The popular Python packages have a standard abbreviation that you will see referenced in literature. Technically, you could create any alias (using our variable naming rules): `curts_favorite_package`, `package1`, `a`, ... but you'll find that `np` is always used for `numpy` in the literature.\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "### 2.1.1. Creating a 1-dimensional `ndarray`\n",
    "\n",
    "There are several ways that we can create an array of values from scratch:\n",
    "\n",
    "1. Passing a Python list containing the values\n",
    "2. Generating a sequence (range) of values (useful for plotting, or evaluating a function at different points)\n",
    "3. Generating $n$ values evenly distributed between a start and end point (useful for plotting, or evaluating a function at different points)\n",
    "4. Generating $n$ random values\n",
    "\n",
    "Examples of each of these is provided in the code below. Using a Python list is pretty straightforward: simply pass the list (or a variable name that references a list) to the `np.array(list)` function. \n",
    "\n",
    "The \"array range\" or `np.arange(start, stop, step)` allows us to generate an array as an arithmetic sequence. We define the start, stop and step values as parameters in the function. The start value will be the first element in the array. The step value is the number by which we count to generate the sequence (this can be real positive or negative number). The sequence will continue **up to, but not including** the stop value.\n",
    "\n",
    "There are two related functions, `np.linspace(start, stop, n)` and `np.logspace(start, stop, n)`, that allow us to generate $n$ elements between a start and stop value. Unlike the `np.arange`, both the start and stop values **are included** in the array. As the names implies, `np.linspace` will distribute the values linearly and `np.logspace` will distribute values logarithmically. When using `np.logspace` the start and top are provided in terms of the power of 10, forming a range [$10^{start}, 10^{stop}$]. This can be helpful when evaluating a function that will be plotted on a log scale.\n",
    "\n",
    "Finally, we can use the `np.random` module to generate random numbers. This module contains a function (`np.random.random(n)`) that generates a 1 $\\times$ $n$ array of random numbers from a flat interval [0, 1). If you need to sample from other probability distributions, or generate random integers, there are other functions available in [`np.random`](https://numpy.org/doc/stable/reference/random/index.html) that you can look up and use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_from_list: [1 2 3]\n",
      "arr_range: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "arr_logspace: [  1.           3.16227766  10.          31.6227766  100.        ]\n",
      "arr_random: [0.45429797 0.82680174 0.91065913 0.79632915 0.27170355 0.45329061]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create an array from a list\n",
    "# the parameter is a list of values (or a variable name that represents a list)\n",
    "arr_from_list = np.array([1, 2, 3])\n",
    "print(f'array_from_list: {arr_from_list}')\n",
    "\n",
    "# create an array as a sequence of values\n",
    "# the parameters are the starting value, the stop value (which is not included), and the step value\n",
    "arr_range = np.arange(1, 11, 1)\n",
    "print(f'arr_range: {arr_range}')\n",
    "\n",
    "# create an array of 5 values, logarithmically distributed between 1 (10^0) and 100 (10^2)\n",
    "arr_logspace = np.logspace(0, 2, 5)\n",
    "print(f'arr_logspace: {arr_logspace}')\n",
    "\n",
    "# create an array of random values between 0, 1\n",
    "# the parameter is the number of values\n",
    "arr_random = np.random.random(6)\n",
    "print(f'arr_random: {arr_random}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Manipulating the data in an `ndarray`\n",
    "\n",
    "Indexing and slicing the `ndarray` works just like `list`, so you can use the same techniques that we learned in Unit 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Array: [10  9  8  7  6  5  4  3  2  1]\n",
      "First 5 Items: [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# the array uses the same indexing/slicing syntax as a Python list\n",
    "arr_range_reversed = arr_range[::-1]\n",
    "print(f'Reversed Array: {arr_range_reversed}')\n",
    "\n",
    "arr_range_topfive = arr_range[:5]\n",
    "print(f'First 5 Items: {arr_range_topfive}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike a standard Python `list`, we can apply math operators directly to an `ndarray`. This will apply the operation \"element-wise\" (to each item in the array individually). For example, to square all of the values in the array, we just square the array object. The `numpy` code takes care of the loop for us behind the scenes, so a list comprehension is not required. Because of how the `numpy` library is programmed, this will be much faster on large datasets versus list comprehensions. The return value is a new `ndarray`, which can be saved to a variable name. The existing array is not modified by this operation, but we can use the same name to save over it if we choose to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,   9,  16,  25,  36,  49,  64,  81, 100], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_range**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing other mathematical operations on an array, we will use versions of the math functions that are built-in to the `numpy` package -- not the basic `math` module functions. These versions will be set up to process the array data efficiently. In general, these will have the same names as those functions from the `math` module. We preface the function name with `np.` to indicate that we want the function that is coming from `numpy`. In the example below, the `sin` function has a parameter which takes an `ndarray` object, and returns another `ndarray` with the result.\n",
    "\n",
    "Refer to the [Mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html) section of the documentation for more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4388316 , 0.73576917, 0.78990811, 0.71479376, 0.26837288,\n",
       "       0.43792619])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sin(arr_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ndarray` object also has methods that can be used to calculate basic statistics on the array values. These functions are called by writing the variable name, and then the function name, seperated by a period. No additional parameters are necessary, but we still must include the empty parentheses (`()`) to indicate that we are calling the function.\n",
    "\n",
    "```\n",
    "<variablename>.<functionname>()\n",
    "```\n",
    "\n",
    "Some examples of useful functions are given in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Value: 0.2717035487171289\n",
      "Maximum Value: 0.9106591302688617\n",
      "Mean: 0.618847023751161\n",
      "Standard Deviation: 0.23625314178424695\n",
      "Sum: 3.7130821425069658\n",
      "Cumulative Sum: [0.45429797 1.28109971 2.19175884 2.98808798 3.25979153 3.71308214]\n"
     ]
    }
   ],
   "source": [
    "print(f'Minimum Value: {arr_random.min()}')\n",
    "print(f'Maximum Value: {arr_random.max()}')\n",
    "print(f'Mean: {arr_random.mean()}')\n",
    "print(f'Standard Deviation: {arr_random.std()}')\n",
    "print(f'Sum: {arr_random.sum()}')\n",
    "print(f'Cumulative Sum: {arr_random.cumsum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Saving and Loading Files\n",
    "\n",
    "At some point, you'll need to save your results to a file for storage or to share with a colleague. For our purposes, we'll demonstrate the use of plain text files for storing data. These are files that you'll be able to open and read in a text viewer like Notepad, or import into a spreadsheet. You can also save data in a binary format that will take up less space on your hard drive. However, this won't be easily human-readable, so we'll skip it for now.\n",
    "\n",
    "To save our `ndarray` to a text file, use the [`np.savetxt`](https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html) function. This requires you to provide a filename, and an `ndarray` as parameters. Optionally, you can apply formatting to the results, or change how columns in your array are separated. The default is a space (`' '`), but you may wish to set this to a comma (`','`) to create a comma-separated (csv) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../../output/unit2_arr_range.txt', arr_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter gives the path to the file that we want to create, including the new file name. If we just used a file name (no directory name) the file would be saved in the \"current working directory\", which is the directory where this Jupyter Notebook resides. Often, it's desirable to separate code and data/output files in a project to reduce clutter, so we have chosen to use a different storage location for this output.\n",
    "\n",
    "For anyone familiar with working on the Windows or Linux command-line shell, the directory notation will be familiar. The double-period (`..`) means go up one level in the directory tree from where we are right now. \n",
    "\n",
    "- python-engineering-analytics\n",
    "  - assets\n",
    "  - data\n",
    "  - output\n",
    "  - units\n",
    "    - 01-introduction\n",
    "    - 02-loading-data\n",
    "      - **unit02-lesson.ipynb** <- we are here\n",
    "      - unit02-problems.ipynb\n",
    "      - unit02-solutions.ipynb\n",
    "    - ...\n",
    "\n",
    "From where we are now, in the `02-loading-data` directory, we go up one level (`../`) to the `units` directory. Then, we go up another level (`../`) to the `python-engineering-analytics` directory. Then we can go down into the `output/` directory and finally assign a file name of `unit2_arr_range.txt`. Chaining these together gives us the filename string from the example.\n",
    "\n",
    "After you have run this cell on your computer, you should see a new file appear in the output directory, called `unit2_arr_range.txt`. Open this file and you will see the array values, one per line. \n",
    "\n",
    "Loading a file is also a single line of code using `np.loadtxt`. If we changed the formatting of the file that we saved (such as using a comma the delimiter character, we'll need to supply that parameter to the function also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_range_reload = np.loadtxt('../../output/unit2_arr_range.txt')\n",
    "arr_range_reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4. Multi-Dimensional Arrays\n",
    "\n",
    "So far, we have looked only at 1-dimensional arrays (vectors). However, as the name suggests, the `ndarray` object can also handle 2-dimensional matrices and even higher-order structures. The `../../data/` directory houses two csv files (comma-separated) that each contains a 2-dimensional, 10 $\\times$ 10 matrix: `matrix_A.csv` and `matrix_B.csv`. We'll load those files into memory, and use them for the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.loadtxt('../../data/matrix_A.csv', delimiter=',')\n",
    "B = np.loadtxt('../../data/matrix_B.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index or slice multi-dimensional arrays just like we did with 1-dimensional arrays. Inside of the square brackets (`[]`), we just have an index or slice associated with each dimension. These are separated by commas.\n",
    "\n",
    "```\n",
    "<ndarraynamee>[<rowslice>, <columnslice>]\n",
    "```\n",
    "\n",
    "If you want to return all of a row or column, use the colon (`:`) in that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.592, 0.07 , 0.411, 0.96 , 0.833, 0.77 , 0.993, 0.452, 0.343,\n",
       "        0.464],\n",
       "       [0.221, 0.92 , 0.681, 0.949, 0.911, 0.106, 0.068, 0.85 , 0.231,\n",
       "        0.117],\n",
       "       [0.934, 0.72 , 0.409, 0.115, 0.128, 0.446, 0.981, 0.541, 0.04 ,\n",
       "        0.686],\n",
       "       [0.963, 0.808, 0.247, 0.399, 0.465, 0.087, 0.859, 0.348, 0.383,\n",
       "        0.255],\n",
       "       [0.607, 0.045, 0.204, 0.045, 0.145, 0.905, 0.694, 0.064, 0.241,\n",
       "        0.256],\n",
       "       [0.972, 0.995, 0.65 , 0.218, 0.367, 0.018, 0.139, 0.054, 0.862,\n",
       "        0.558],\n",
       "       [0.429, 0.069, 0.114, 0.15 , 0.018, 0.616, 0.042, 0.963, 0.77 ,\n",
       "        0.904],\n",
       "       [0.751, 0.544, 0.981, 0.917, 0.685, 0.658, 0.113, 0.151, 0.087,\n",
       "        0.281],\n",
       "       [0.571, 0.   , 0.586, 0.044, 0.936, 0.893, 0.229, 0.257, 0.201,\n",
       "        0.05 ],\n",
       "       [0.732, 0.21 , 0.581, 0.357, 0.687, 0.348, 0.261, 0.147, 0.57 ,\n",
       "        0.26 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the entire matrix\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the value at row=1, column=1\n",
    "A[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.592, 0.07 , 0.411, 0.96 , 0.833, 0.77 , 0.993, 0.452, 0.343,\n",
       "        0.464],\n",
       "       [0.221, 0.92 , 0.681, 0.949, 0.911, 0.106, 0.068, 0.85 , 0.231,\n",
       "        0.117],\n",
       "       [0.934, 0.72 , 0.409, 0.115, 0.128, 0.446, 0.981, 0.541, 0.04 ,\n",
       "        0.686]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first 3 rows, all columns\n",
    "A[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.911, 0.106, 0.068])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view row 1, columns 4-6\n",
    "A[1, 4:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also introduce the matrix multiplication operator (`@`), which will perform row $\\times$ column multiplication on vectors and matrices. As you can see in the example below, matrices `A` and `B` are actually inverses of each other, because their matrix product is the idenity matrix.\n",
    "\n",
    "We'll use the `np.round` function to perform an element-wise rounding (to 1 decimal place) on each of the values to clean up the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,  0.],\n",
       "       [-0.,  1., -0.,  0., -0., -0.,  0.,  0.,  0.,  0.],\n",
       "       [-0.,  0.,  1., -0., -0.,  0., -0., -0., -0.,  0.],\n",
       "       [-0.,  0.,  0.,  1.,  0., -0., -0., -0., -0.,  0.],\n",
       "       [-0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -0., -0.],\n",
       "       [-0., -0.,  0., -0.,  0.,  1., -0., -0., -0.,  0.],\n",
       "       [-0.,  0., -0.,  0.,  0.,  0.,  1.,  0.,  0., -0.],\n",
       "       [-0.,  0.,  0., -0.,  0., -0., -0.,  1., -0.,  0.],\n",
       "       [-0.,  0.,  0., -0.,  0., -0., -0., -0.,  1.,  0.],\n",
       "       [-0.,  0.,  0., -0.,  0., -0., -0., -0., -0.,  1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication of A and B\n",
    "C = A@B\n",
    "np.round(C, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can learn about the size of an `ndarray` by accessing its `size` or `shape` properties. These are not functions, so we do not include the parentheses (`()`) after the name.\n",
    "\n",
    "- `size` provides the total number of elements in the array\n",
    "- `shape` provides the length of the array in each dimension\n",
    "\n",
    "For a 1-dimensional array, such as `arr_random`, we see that the shape only has one value of `5`, but it is enclosed in parenthesis. This is because the `shape` property has a type of `tuple`. For our purposes, we can view a `tuple` as a special type of list. The `shape` of the 2-dimensional matrix shows us that the row count and column count are each 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_random.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, the computer is storing your n-dimensional array is stored as a single 1-dimensional array and our ability to index by rows and columns is really just a convenience. We can ask the computer to change the shape, so that we can index the array differently. \n",
    "\n",
    "We learned how to generated 1-dimensional arrays, so how do we manipulate these into matrices? With the `reshape` function, we can supply a new shape (as a `tuple` or `list`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45429797, 0.82680174],\n",
       "       [0.91065913, 0.79632915],\n",
       "       [0.27170355, 0.45329061]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_random.reshape([3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45429797, 0.82680174, 0.91065913],\n",
       "       [0.79632915, 0.27170355, 0.45329061]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_random.reshape([2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these examples, we see that `numpy` is reshaping the data in *row-major* order (C-style). This means that each element is filled into the first row, across the columns, before moving on to the next row. For another clear example, see below. Here, we create a 100-element sequence (using the default values of starting at 0 and counting by 1), and reshape that to have 20 rows and 5 columns. Notice that we can count across the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24],\n",
       "       [25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34],\n",
       "       [35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44],\n",
       "       [45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54],\n",
       "       [55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64],\n",
       "       [65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74],\n",
       "       [75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84],\n",
       "       [85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94],\n",
       "       [95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(100).reshape([20, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. The `pandas` package for mixed-format data\n",
    "\n",
    "While `numpy` is extremely useful (and efficient) for numerical analysis and matrix math, sometimes it is more convenient to work with a dataset that has named columns, or one that contains a mix of datatypes (dates, strings, numbers) that are not supported in a single `ndarray`. This is where the [`pandas`](https://pandas.pydata.org/) package can be extremely useful. To import the `pandas` package, we need to add the following line of code:\n",
    "\n",
    "> import pandas as pd\n",
    "\n",
    "Like the abbreviation `np` for `numpy`, it is customary to use the abbreviation of `pd` for `pandas`.\n",
    "\n",
    "In `pandas`, data is organized in an object called a `DataFrame`. Think about a `DataFrame` as a table in a spreadsheet, with named columns and a row index. The row index can be just the row number, or we can assign an index of a different data type. \n",
    "\n",
    "### 2.2.1. Loading data into a `pandas.DataFrame`\n",
    "\n",
    "While we can build a `DataFrame` from scratch, our mission is to analyze engineering data so we're most interested in loading data that already exists. There are three primary forms that we consider loading data:\n",
    "\n",
    "1. A comma- or tab-delimited plain text file, such as a csv or txt\n",
    "2. An Excel spreadsheet file (xlsx)\n",
    "3. The result set from a SQL SELECT query\n",
    "\n",
    "Once the `DataFrame` is populated, it doesn't matter where the data came from. The process for using these sources is similar, but we'll provide an example of each. First, we'll look at a 2-column csv file using the `pd.read_csv` function. The directory path is written in the same way as we learned above.\n",
    "\n",
    "Once we read the file into a `DataFrame` object, it can be helpful to use the `head` function to view the top 5 rows. Note that our columns in a `DataFrame` have names associated with them, which are displayed when we print out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>fid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833318</td>\n",
       "      <td>0.463005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.834152</td>\n",
       "      <td>0.461075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.834985</td>\n",
       "      <td>0.462688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.835818</td>\n",
       "      <td>0.465777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.836652</td>\n",
       "      <td>0.468805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.837485</td>\n",
       "      <td>0.470081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.838318</td>\n",
       "      <td>0.469796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.839151</td>\n",
       "      <td>0.469420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.839985</td>\n",
       "      <td>0.467093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.840818</td>\n",
       "      <td>0.465238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    minutes       fid\n",
       "0  0.833318  0.463005\n",
       "1  0.834152  0.461075\n",
       "2  0.834985  0.462688\n",
       "3  0.835818  0.465777\n",
       "4  0.836652  0.468805\n",
       "5  0.837485  0.470081\n",
       "6  0.838318  0.469796\n",
       "7  0.839151  0.469420\n",
       "8  0.839985  0.467093\n",
       "9  0.840818  0.465238"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read a .csv file into a DataFrame variable named df\n",
    "df = pd.read_csv('../../data/pcr-polyethylene_gc-fid.csv')\n",
    "\n",
    "# display the top n rows in the DataFrame named df (defaults to n=5 if blank)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading an Excel file is very similar, but uses a function called `pd.read_excel`. In addition to the file path, we need to identify the name of the worksheet in the file, using the parameter `sheet_name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data may also be present in a database that you can query into a `DataFrame`. The langage for querying a relational database, called *structured query language* or **SQL** could be a unit unto itself. So, this will be a simple introduction to introduce the capability. If you are (or later become) familiar with SQL, you'll be able to integrate this with your Python analytics skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Selecting data from a `DataFrame`\n",
    "\n",
    "Selecting data from the `pd.DataFrame` is similar to what we have demonstrated for the Python `list` and `np.ndarray`, but there are a few key differences. First, we can select individual columns by using the column name. The row index value is maintained, and is still displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.463005\n",
       "1        0.461075\n",
       "2        0.462688\n",
       "3        0.465777\n",
       "4        0.468805\n",
       "           ...   \n",
       "53179    3.115661\n",
       "53180    3.084669\n",
       "53181    3.071105\n",
       "53182    3.082195\n",
       "53183    3.111270\n",
       "Name: fid, Length: 53184, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the entire column named 'fid'\n",
    "df['fid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we apply functions such as `head(n)` or `tail(n)` to just the selected column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53174    3.154023\n",
       "53175    3.181481\n",
       "53176    3.192894\n",
       "53177    3.182362\n",
       "53178    3.152016\n",
       "53179    3.115661\n",
       "53180    3.084669\n",
       "53181    3.071105\n",
       "53182    3.082195\n",
       "53183    3.111270\n",
       "Name: fid, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fid'].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select specific rows, we need to access the `DataFrame.iloc` property, as shown below. Here, we use `iloc[10:20]` is used to get the slice of rows on the interval [10, 20). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>fid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.841651</td>\n",
       "      <td>0.464645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.842485</td>\n",
       "      <td>0.464104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.843318</td>\n",
       "      <td>0.463338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.844151</td>\n",
       "      <td>0.461775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.463340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845818</td>\n",
       "      <td>0.463046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.846651</td>\n",
       "      <td>0.460759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.847485</td>\n",
       "      <td>0.457886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.848318</td>\n",
       "      <td>0.458167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.849151</td>\n",
       "      <td>0.459737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     minutes       fid\n",
       "10  0.841651  0.464645\n",
       "11  0.842485  0.464104\n",
       "12  0.843318  0.463338\n",
       "13  0.844151  0.461775\n",
       "14  0.844985  0.463340\n",
       "15  0.845818  0.463046\n",
       "16  0.846651  0.460759\n",
       "17  0.847485  0.457886\n",
       "18  0.848318  0.458167\n",
       "19  0.849151  0.459737"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More useful can be filtering based on values in the data itself. For instance, we can use a filter to select all rows of the `DataFrame` where the test time is greater than or equal to 10 minutes. Let's dissect this a little further. The inner expression, `df['minutes'] >= 10`, creates a series of `True`/`False` values, one for each row of the data set. This series of `True`/`False` is then used to select the rows of `df` in the outer expression. Any rows for which that condition is `True` are selected and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>fid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>10.000652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11002</th>\n",
       "      <td>10.001485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003</th>\n",
       "      <td>10.002319</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11004</th>\n",
       "      <td>10.003152</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11005</th>\n",
       "      <td>10.003985</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53179</th>\n",
       "      <td>45.148349</td>\n",
       "      <td>3.115661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53180</th>\n",
       "      <td>45.149182</td>\n",
       "      <td>3.084669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53181</th>\n",
       "      <td>45.150015</td>\n",
       "      <td>3.071105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53182</th>\n",
       "      <td>45.150848</td>\n",
       "      <td>3.082195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53183</th>\n",
       "      <td>45.151682</td>\n",
       "      <td>3.111270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42183 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         minutes       fid\n",
       "11001  10.000652  0.000000\n",
       "11002  10.001485  0.000000\n",
       "11003  10.002319  0.000000\n",
       "11004  10.003152  0.000000\n",
       "11005  10.003985  0.000000\n",
       "...          ...       ...\n",
       "53179  45.148349  3.115661\n",
       "53180  45.149182  3.084669\n",
       "53181  45.150015  3.071105\n",
       "53182  45.150848  3.082195\n",
       "53183  45.151682  3.111270\n",
       "\n",
       "[42183 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['minutes'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Calculating basic statistics\n",
    "\n",
    "Just like the `np.ndarray`, the `pd.DataFrame` has basic statistical functions. If you execute these on the `DataFrame`, you'll apply the function to each column. Alternatively, we can select a column (as we learned above) and then apply the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Value: minutes    0.833318\n",
      "fid        0.000000\n",
      "dtype: float64\n",
      "Maximum Value: minutes     45.151682\n",
      "fid        514.773091\n",
      "dtype: float64\n",
      "Mean: minutes    22.992500\n",
      "fid         6.628462\n",
      "dtype: float64\n",
      "Standard Deviation: minutes    12.793970\n",
      "fid        23.609411\n",
      "dtype: float64\n",
      "Sum: minutes    1.222833e+06\n",
      "fid        3.525281e+05\n",
      "dtype: float64\n",
      "Cumulative Sum:             minutes            fid\n",
      "0      8.333182e-01       0.463005\n",
      "1      1.667470e+00       0.924081\n",
      "2      2.502455e+00       1.386769\n",
      "3      3.338273e+00       1.852546\n",
      "4      4.174924e+00       2.321351\n",
      "...             ...            ...\n",
      "53179  1.222653e+06  352515.771460\n",
      "53180  1.222698e+06  352518.856128\n",
      "53181  1.222743e+06  352521.927233\n",
      "53182  1.222788e+06  352525.009428\n",
      "53183  1.222833e+06  352528.120698\n",
      "\n",
      "[53184 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# calculate statistics for every column in the DataFrame\n",
    "print(f'Minimum Value: {df.min()}')\n",
    "print(f'Maximum Value: {df.max()}')\n",
    "print(f'Mean: {df.mean()}')\n",
    "print(f'Standard Deviation: {df.std()}')\n",
    "print(f'Sum: {df.sum()}')\n",
    "print(f'Cumulative Sum: {df.cumsum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Value: 0.0\n",
      "Maximum Value: 514.7730906\n",
      "Mean: 6.6284619565696214\n",
      "Standard Deviation: 23.60941069708044\n",
      "Sum: 352528.120698199\n",
      "Cumulative Sum: 0             0.463005\n",
      "1             0.924081\n",
      "2             1.386769\n",
      "3             1.852546\n",
      "4             2.321351\n",
      "             ...      \n",
      "53179    352515.771460\n",
      "53180    352518.856128\n",
      "53181    352521.927233\n",
      "53182    352525.009428\n",
      "53183    352528.120698\n",
      "Name: fid, Length: 53184, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate statistics for just the 'fid' column in the DataFrame\n",
    "print(f'Minimum Value: {df[\"fid\"].min()}')\n",
    "print(f'Maximum Value: {df[\"fid\"].max()}')\n",
    "print(f'Mean: {df[\"fid\"].mean()}')\n",
    "print(f'Standard Deviation: {df[\"fid\"].std()}')\n",
    "print(f'Sum: {df[\"fid\"].sum()}')\n",
    "print(f'Cumulative Sum: {df[\"fid\"].cumsum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works, but `pandas` gives us an easier way - the `describe` function. You can use this to calculate the mean, min, max, stdev and quartiles of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>fid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53184.000000</td>\n",
       "      <td>53184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.992500</td>\n",
       "      <td>6.628462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.793970</td>\n",
       "      <td>23.609411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.833318</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.912909</td>\n",
       "      <td>0.358469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.992500</td>\n",
       "      <td>2.298928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.072091</td>\n",
       "      <td>4.849412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.151682</td>\n",
       "      <td>514.773091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            minutes           fid\n",
       "count  53184.000000  53184.000000\n",
       "mean      22.992500      6.628462\n",
       "std       12.793970     23.609411\n",
       "min        0.833318      0.000000\n",
       "25%       11.912909      0.358469\n",
       "50%       22.992500      2.298928\n",
       "75%       34.072091      4.849412\n",
       "max       45.151682    514.773091"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Saving a `DataFrame` to a file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../output/unit2_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2857618fbf4d4bb3d9a88a0331cc9f5539aea2b45b45163c4b048952b7884495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
